{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r\"./data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "m, n = data.shape\n",
    "np.random.shuffle(data)\n",
    "\n",
    "data_dev = data[0:1000].T\n",
    "Y_dev = data_dev[0]\n",
    "X_dev = data_dev[1:n]\n",
    "X_dev = X_dev / 255.\n",
    "\n",
    "data_train = data[1000:m].T\n",
    "Y_train = data_train[0]\n",
    "X_train = data_train[1:n]\n",
    "X_train = X_train / 255.\n",
    "_, m_train = X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the data is split into a development set (data_dev) and a training set (data_train). The pixel values are normalized to a range between 0 and 1 by dividing by 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our NN will have a simple two-layer architecture. Input layer $a^{[0]}$ will have 784 units corresponding to the 784 pixels in each 28x28 input image. A hidden layer $a^{[1]}$ will have 10 units with ReLU activation, and finally our output layer $a^{[2]}$ will have 10 units corresponding to the ten digit classes with softmax activation.\n",
    "\n",
    "**Forward propagation**\n",
    "\n",
    "$$Z^{[1]} = W^{[1]} X + b^{[1]}$$\n",
    "$$A^{[1]} = g_{\\text{ReLU}}(Z^{[1]}))$$\n",
    "$$Z^{[2]} = W^{[2]} A^{[1]} + b^{[2]}$$\n",
    "$$A^{[2]} = g_{\\text{softmax}}(Z^{[2]})$$\n",
    "\n",
    "**Backward propagation**\n",
    "\n",
    "$$dZ^{[2]} = A^{[2]} - Y$$\n",
    "$$dW^{[2]} = \\frac{1}{m} dZ^{[2]} A^{[1]T}$$\n",
    "$$dB^{[2]} = \\frac{1}{m} \\Sigma {dZ^{[2]}}$$\n",
    "$$dZ^{[1]} = W^{[2]T} dZ^{[2]} .* g^{[1]\\prime} (z^{[1]})$$\n",
    "$$dW^{[1]} = \\frac{1}{m} dZ^{[1]} A^{[0]T}$$\n",
    "$$dB^{[1]} = \\frac{1}{m} \\Sigma {dZ^{[1]}}$$\n",
    "\n",
    "**Parameter updates**\n",
    "\n",
    "$$W^{[2]} := W^{[2]} - \\alpha dW^{[2]}$$\n",
    "$$b^{[2]} := b^{[2]} - \\alpha db^{[2]}$$\n",
    "$$W^{[1]} := W^{[1]} - \\alpha dW^{[1]}$$\n",
    "$$b^{[1]} := b^{[1]} - \\alpha db^{[1]}$$\n",
    "\n",
    "**Vars and shapes**\n",
    "\n",
    "Forward prop\n",
    "\n",
    "- $A^{[0]} = X$: 784 x m\n",
    "- $Z^{[1]} \\sim A^{[1]}$: 10 x m\n",
    "- $W^{[1]}$: 10 x 784 (as $W^{[1]} A^{[0]} \\sim Z^{[1]}$)\n",
    "- $B^{[1]}$: 10 x 1\n",
    "- $Z^{[2]} \\sim A^{[2]}$: 10 x m\n",
    "- $W^{[1]}$: 10 x 10 (as $W^{[2]} A^{[1]} \\sim Z^{[2]}$)\n",
    "- $B^{[2]}$: 10 x 1\n",
    "\n",
    "Backprop\n",
    "\n",
    "- $dZ^{[2]}$: 10 x m ($~A^{[2]}$)\n",
    "- $dW^{[2]}$: 10 x 10\n",
    "- $dB^{[2]}$: 10 x 1\n",
    "- $dZ^{[1]}$: 10 x m ($~A^{[1]}$)\n",
    "- $dW^{[1]}$: 10 x 10\n",
    "- $dB^{[1]}$: 10 x 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This function intializes the parameters of the neural network: weights (w1, w2) and biases (b1, b2) for the input and hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_param():\n",
    "    w1 = np.random.rand(10, 784)-0.5\n",
    "    b1 = np.random.rand(10, 1)-0.5\n",
    "    w2 = np.random.rand(10, 10)-0.5\n",
    "    b2 = np.random.rand(10, 1)-0.5\n",
    "    return w1, b1, w2, b2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- These functions define the activation functions used in the neural network: ReLU (Rectified Linear Unit) for the hidden layer and softmax for the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(Z):\n",
    "    return np.maximum(Z, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(Z):\n",
    "    A = np.exp(Z) / sum(np.exp(Z))\n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This function performs forward propagation, computing the activations of each layer sequentially until the final output is obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(w1, b1, w2, b2, X):\n",
    "    z1 = w1.dot(X)+b1\n",
    "    a1 = ReLU(z1)\n",
    "    z2 = w2.dot(a1)+b2\n",
    "    a2 = softmax(z2)\n",
    "    return z1, a1, z2, a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(Y):\n",
    "    one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
    "    one_hot_Y[np.arange(Y.size), Y] = 1\n",
    "    one_hot_Y = one_hot_Y.T\n",
    "    return one_hot_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative_ReLU(Z):\n",
    "    return Z>0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This function computes the gradients of the loss function with respect to the parameters of the network during backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_prop(z1, a1, z2, a2, w2, Y, X):\n",
    "    one_hot_Y = one_hot(Y)\n",
    "    dZ2 = a2-one_hot_Y\n",
    "    dW2 = 1/m * dZ2.dot(a1.T)\n",
    "    db2 = 1/m * np.sum(dZ2)\n",
    "    dZ1 = w2.T.dot(dZ2) * derivative_ReLU(z1)\n",
    "    dW1 = 1/m * dZ1.dot(X.T)\n",
    "    db1 = 1/m * np.sum(dZ1)\n",
    "    return dW1, db1, dW2, db2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This function updates the parameters of the neural network using gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):\n",
    "    W1 = W1-alpha*dW1\n",
    "    b1 = b1-alpha*db1\n",
    "    W2 = W2-alpha*dW2\n",
    "    b2 = b2-alpha*db2\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(a2):\n",
    "    return np.argmax(a2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(predictions, Y):\n",
    "    print(predictions, Y)\n",
    "    return np.sum(predictions == Y) / Y.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This function performs gradient descent to train the neural network, iterating over a specified number of epochs and updating the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, Y, iterations, alpha):\n",
    "    w1, b1, w2, b2 = init_param()\n",
    "    for i in range(iterations):\n",
    "        z1, a1, z2, a2 = forward_prop(w1, b1, w2, b2, X)\n",
    "        dW1, db1, dW2, db2 = back_prop(z1, a1, z2, a2, w2, Y, X)\n",
    "        w1, b1, w2, b2 = update_params(w1, b1, w2, b2, dW1, db1, dW2, db2, alpha)\n",
    "        if i%10 == 0:\n",
    "            print(\"iterations: \", i)\n",
    "            print(\"Accuracy: \", get_accuracy(get_predictions(a2), Y))\n",
    "    return w1, b1, w2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterations:  0\n",
      "[1 4 6 ... 1 6 4] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.14204878048780487\n",
      "iterations:  10\n",
      "[3 4 3 ... 0 6 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.281780487804878\n",
      "iterations:  20\n",
      "[3 4 3 ... 2 6 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.3700487804878049\n",
      "iterations:  30\n",
      "[3 4 3 ... 2 6 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.4473170731707317\n",
      "iterations:  40\n",
      "[3 4 3 ... 2 6 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.5071219512195122\n",
      "iterations:  50\n",
      "[3 4 4 ... 2 6 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.5518048780487805\n",
      "iterations:  60\n",
      "[3 4 4 ... 2 6 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.5872195121951219\n",
      "iterations:  70\n",
      "[2 4 4 ... 2 6 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.618780487804878\n",
      "iterations:  80\n",
      "[2 4 4 ... 2 6 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.6462926829268293\n",
      "iterations:  90\n",
      "[2 4 4 ... 2 6 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.6712439024390244\n",
      "iterations:  100\n",
      "[2 4 4 ... 2 6 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.690390243902439\n",
      "iterations:  110\n",
      "[2 4 4 ... 2 6 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.7061951219512195\n",
      "iterations:  120\n",
      "[2 4 4 ... 2 6 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.7200975609756097\n",
      "iterations:  130\n",
      "[3 4 4 ... 2 6 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.7336585365853658\n",
      "iterations:  140\n",
      "[3 4 4 ... 2 6 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.7448292682926829\n",
      "iterations:  150\n",
      "[3 4 4 ... 2 6 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.7541219512195122\n",
      "iterations:  160\n",
      "[3 4 4 ... 2 6 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.7629268292682927\n",
      "iterations:  170\n",
      "[3 4 4 ... 2 6 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.7704390243902439\n",
      "iterations:  180\n",
      "[3 4 4 ... 2 6 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.7775121951219512\n",
      "iterations:  190\n",
      "[3 4 4 ... 2 6 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.783829268292683\n",
      "iterations:  200\n",
      "[3 4 4 ... 2 6 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.7887317073170732\n",
      "iterations:  210\n",
      "[3 4 4 ... 2 6 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.7933414634146342\n",
      "iterations:  220\n",
      "[3 7 4 ... 2 6 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.7978780487804878\n",
      "iterations:  230\n",
      "[3 7 4 ... 2 6 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.8021463414634147\n",
      "iterations:  240\n",
      "[3 7 4 ... 2 6 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.8060243902439025\n",
      "iterations:  250\n",
      "[3 7 4 ... 2 2 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.809609756097561\n",
      "iterations:  260\n",
      "[3 7 4 ... 2 2 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.8130975609756097\n",
      "iterations:  270\n",
      "[3 7 4 ... 2 2 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.8161463414634146\n",
      "iterations:  280\n",
      "[3 7 4 ... 2 2 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.8195853658536585\n",
      "iterations:  290\n",
      "[3 7 4 ... 2 2 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.8222926829268292\n",
      "iterations:  300\n",
      "[3 7 4 ... 2 2 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.8252439024390243\n",
      "iterations:  310\n",
      "[3 7 4 ... 2 2 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.8274878048780487\n",
      "iterations:  320\n",
      "[3 7 4 ... 2 2 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.8305609756097561\n",
      "iterations:  330\n",
      "[3 7 4 ... 2 2 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.8324878048780487\n",
      "iterations:  340\n",
      "[3 7 4 ... 2 2 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.8346341463414634\n",
      "iterations:  350\n",
      "[3 7 4 ... 2 2 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.8365609756097561\n",
      "iterations:  360\n",
      "[3 7 4 ... 2 2 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.8381951219512195\n",
      "iterations:  370\n",
      "[3 7 4 ... 2 2 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.8402926829268292\n",
      "iterations:  380\n",
      "[3 7 4 ... 2 2 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.8420487804878048\n",
      "iterations:  390\n",
      "[3 7 4 ... 2 2 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.8433414634146341\n",
      "iterations:  400\n",
      "[3 7 4 ... 2 2 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.8450731707317073\n",
      "iterations:  410\n",
      "[3 7 4 ... 2 2 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.846609756097561\n",
      "iterations:  420\n",
      "[3 7 4 ... 2 2 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.8478048780487805\n",
      "iterations:  430\n",
      "[3 7 4 ... 2 2 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.8490731707317073\n",
      "iterations:  440\n",
      "[3 7 4 ... 2 2 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.8506829268292683\n",
      "iterations:  450\n",
      "[3 7 4 ... 2 2 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.8517073170731707\n",
      "iterations:  460\n",
      "[3 7 4 ... 2 2 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.8529268292682927\n",
      "iterations:  470\n",
      "[3 7 4 ... 2 2 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.8540731707317073\n",
      "iterations:  480\n",
      "[3 7 4 ... 2 2 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.8552439024390244\n",
      "iterations:  490\n",
      "[3 7 4 ... 2 2 3] [5 7 4 ... 2 2 3]\n",
      "Accuracy:  0.8562439024390244\n"
     ]
    }
   ],
   "source": [
    "w1, b1, w2, b2 = gradient_descent(X_train, Y_train, 500, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This function makes predictions using the trained neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(X, W1, b1, W2, b2):\n",
    "    _, _, _, A2 = forward_prop(W1, b1, W2, b2, X)\n",
    "    predictions = get_predictions(A2)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- These functions are for testing predictions and calculating accuracy on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prediction(index, W1, b1, W2, b2):\n",
    "    current_image = X_train[:, index, None]\n",
    "    prediction = make_predictions(X_train[:, index, None], W1, b1, W2, b2)\n",
    "    label = Y_train[index]\n",
    "    print(\"Prediction: \", prediction)\n",
    "    print(\"Label: \", label)\n",
    "\n",
    "    current_image = current_image.reshape((28, 28)) * 255\n",
    "    plt.gray()\n",
    "    plt.imshow(current_image, interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction(0, w1, b1, w2, b2)\n",
    "test_prediction(1, w1, b1, w2, b2)\n",
    "test_prediction(2, w1, b1, w2, b2)\n",
    "test_prediction(3, w1, b1, w2, b2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
